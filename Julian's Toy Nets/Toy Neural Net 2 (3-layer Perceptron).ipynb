{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Neural Net (Fully Connected Perceptron with 1 Hidden Layer)\n",
    "\n",
    "Training on dataset to correlate student grades with study and sleep hours (dataset of size 3, generated by hand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 | Loss: 0.10052943229675293\n",
      "Run 1 | Loss: 0.08454935997724533\n",
      "Run 2 | Loss: 0.0718141719698906\n",
      "Run 3 | Loss: 0.061580922454595566\n",
      "Run 4 | Loss: 0.053287189453840256\n",
      "Run 5 | Loss: 0.04650675877928734\n",
      "Run 6 | Loss: 0.04091576114296913\n",
      "Run 7 | Loss: 0.03626694157719612\n",
      "Run 8 | Loss: 0.0323704294860363\n",
      "Run 9 | Loss: 0.02907949686050415\n",
      "Run 10 | Loss: 0.02627984993159771\n",
      "Run 11 | Loss: 0.02388188987970352\n",
      "Run 12 | Loss: 0.021814806386828423\n",
      "Run 13 | Loss: 0.020022224634885788\n",
      "Run 14 | Loss: 0.018458930775523186\n",
      "Run 15 | Loss: 0.017088431864976883\n",
      "Run 16 | Loss: 0.01588098146021366\n",
      "Run 17 | Loss: 0.014812304638326168\n",
      "Run 18 | Loss: 0.013862325809895992\n",
      "Run 19 | Loss: 0.013014462776482105\n",
      "Run 20 | Loss: 0.012254844419658184\n",
      "Run 21 | Loss: 0.01157184224575758\n",
      "Run 22 | Loss: 0.010955662466585636\n",
      "Run 23 | Loss: 0.010398018173873425\n",
      "Run 24 | Loss: 0.00989183597266674\n",
      "Run 25 | Loss: 0.00943106971681118\n",
      "Run 26 | Loss: 0.00901053473353386\n",
      "Run 27 | Loss: 0.008625737391412258\n",
      "Run 28 | Loss: 0.008272814564406872\n",
      "Run 29 | Loss: 0.007948390208184719\n",
      "Run 30 | Loss: 0.007649507839232683\n",
      "Run 31 | Loss: 0.007373621687293053\n",
      "Run 32 | Loss: 0.007118453737348318\n",
      "Run 33 | Loss: 0.0068820081651210785\n",
      "Run 34 | Loss: 0.006662521976977587\n",
      "Run 35 | Loss: 0.006458453368395567\n",
      "Run 36 | Loss: 0.0062684002332389355\n",
      "Run 37 | Loss: 0.0060911341570317745\n",
      "Run 38 | Loss: 0.0059255510568618774\n",
      "Run 39 | Loss: 0.0057706753723323345\n",
      "Run 40 | Loss: 0.005625593010336161\n",
      "Run 41 | Loss: 0.005489529576152563\n",
      "Run 42 | Loss: 0.005361759569495916\n",
      "Run 43 | Loss: 0.0052416338585317135\n",
      "Run 44 | Loss: 0.0051285638473927975\n",
      "Run 45 | Loss: 0.005022021476179361\n",
      "Run 46 | Loss: 0.004921531770378351\n",
      "Run 47 | Loss: 0.004826636984944344\n",
      "Run 48 | Loss: 0.004736947827041149\n",
      "Run 49 | Loss: 0.004652093630284071\n",
      "Run 50 | Loss: 0.004571738187223673\n",
      "Run 51 | Loss: 0.004495582077652216\n",
      "Run 52 | Loss: 0.00442333472892642\n",
      "Run 53 | Loss: 0.004354743752628565\n",
      "Run 54 | Loss: 0.0042895725928246975\n",
      "Run 55 | Loss: 0.004227605648338795\n",
      "Run 56 | Loss: 0.004168630577623844\n",
      "Run 57 | Loss: 0.004112470895051956\n",
      "Run 58 | Loss: 0.004058951046317816\n",
      "Run 59 | Loss: 0.004007917363196611\n",
      "Run 60 | Loss: 0.003959206398576498\n",
      "Run 61 | Loss: 0.003912692423909903\n",
      "Run 62 | Loss: 0.003868255764245987\n",
      "Run 63 | Loss: 0.0038257641717791557\n",
      "Run 64 | Loss: 0.0037851184606552124\n",
      "Run 65 | Loss: 0.00374619965441525\n",
      "Run 66 | Loss: 0.0037089374382048845\n",
      "Run 67 | Loss: 0.0036732209846377373\n",
      "Run 68 | Loss: 0.0036389753222465515\n",
      "Run 69 | Loss: 0.0036061268765479326\n",
      "Run 70 | Loss: 0.003574596717953682\n",
      "Run 71 | Loss: 0.0035443154629319906\n",
      "Run 72 | Loss: 0.003515225602313876\n",
      "Run 73 | Loss: 0.003487260779365897\n",
      "Run 74 | Loss: 0.003460370935499668\n",
      "Run 75 | Loss: 0.003434494137763977\n",
      "Run 76 | Loss: 0.0034095942974090576\n",
      "Run 77 | Loss: 0.003385612042620778\n",
      "Run 78 | Loss: 0.003362511983141303\n",
      "Run 79 | Loss: 0.0033402417320758104\n",
      "Run 80 | Loss: 0.0033187747467309237\n",
      "Run 81 | Loss: 0.003298065857961774\n",
      "Run 82 | Loss: 0.003278079442679882\n",
      "Run 83 | Loss: 0.0032587952446192503\n",
      "Run 84 | Loss: 0.0032401662319898605\n",
      "Run 85 | Loss: 0.003222171450033784\n",
      "Run 86 | Loss: 0.003204786917194724\n",
      "Run 87 | Loss: 0.0031879779417067766\n",
      "Run 88 | Loss: 0.003171721240505576\n",
      "Run 89 | Loss: 0.0031559912022203207\n",
      "Run 90 | Loss: 0.003140773857012391\n",
      "Run 91 | Loss: 0.0031260389368981123\n",
      "Run 92 | Loss: 0.003111770609393716\n",
      "Run 93 | Loss: 0.003097952576354146\n",
      "Run 94 | Loss: 0.0030845599249005318\n",
      "Run 95 | Loss: 0.003071574727073312\n",
      "Run 96 | Loss: 0.0030589960515499115\n",
      "Run 97 | Loss: 0.0030467903707176447\n",
      "Run 98 | Loss: 0.0030349467415362597\n",
      "Run 99 | Loss: 0.0030234570149332285\n",
      "Run 100 | Loss: 0.0030122995376586914\n",
      "Run 101 | Loss: 0.00300146103836596\n",
      "Run 102 | Loss: 0.0029909454751759768\n",
      "Run 103 | Loss: 0.0029807279352098703\n",
      "Run 104 | Loss: 0.002970794215798378\n",
      "Run 105 | Loss: 0.002961140824481845\n",
      "Run 106 | Loss: 0.0029517479706555605\n",
      "Run 107 | Loss: 0.0029426172841340303\n",
      "Run 108 | Loss: 0.002933734329417348\n",
      "Run 109 | Loss: 0.002925088396295905\n",
      "Run 110 | Loss: 0.0029166806489229202\n",
      "Run 111 | Loss: 0.0029084859415888786\n",
      "Run 112 | Loss: 0.0029005149845033884\n",
      "Run 113 | Loss: 0.0028927435632795095\n",
      "Run 114 | Loss: 0.002885175868868828\n",
      "Run 115 | Loss: 0.0028778009582310915\n",
      "Run 116 | Loss: 0.0028706176672130823\n",
      "Run 117 | Loss: 0.0028636064380407333\n",
      "Run 118 | Loss: 0.0028567786794155836\n",
      "Run 119 | Loss: 0.0028501099441200495\n",
      "Run 120 | Loss: 0.002843606984242797\n",
      "Run 121 | Loss: 0.002837259089574218\n",
      "Run 122 | Loss: 0.0028310706838965416\n",
      "Run 123 | Loss: 0.0028250247705727816\n",
      "Run 124 | Loss: 0.002819119719788432\n",
      "Run 125 | Loss: 0.002813355065882206\n",
      "Run 126 | Loss: 0.002807723358273506\n",
      "Run 127 | Loss: 0.002802217146381736\n",
      "Run 128 | Loss: 0.002796843647956848\n",
      "Run 129 | Loss: 0.0027915870305150747\n",
      "Run 130 | Loss: 0.0027864479925483465\n",
      "Run 131 | Loss: 0.0027814272325485945\n",
      "Run 132 | Loss: 0.0027765126433223486\n",
      "Run 133 | Loss: 0.0027716998010873795\n",
      "Run 134 | Loss: 0.002766998717561364\n",
      "Run 135 | Loss: 0.0027623979840427637\n",
      "Run 136 | Loss: 0.002757897600531578\n",
      "Run 137 | Loss: 0.0027534833643585443\n",
      "Run 138 | Loss: 0.0027491666842252016\n",
      "Run 139 | Loss: 0.00274493801407516\n",
      "Run 140 | Loss: 0.0027408022433519363\n",
      "Run 141 | Loss: 0.0027367407456040382\n",
      "Run 142 | Loss: 0.0027327637653797865\n",
      "Run 143 | Loss: 0.002728864550590515\n",
      "Run 144 | Loss: 0.0027250524144619703\n",
      "Run 145 | Loss: 0.002721308032050729\n",
      "Run 146 | Loss: 0.002717637224122882\n",
      "Run 147 | Loss: 0.002714039059355855\n",
      "Run 148 | Loss: 0.0027105072513222694\n",
      "Run 149 | Loss: 0.0027070415671914816\n",
      "Run 150 | Loss: 0.0027036454994231462\n",
      "Run 151 | Loss: 0.0027003104332834482\n",
      "Run 152 | Loss: 0.0026970356702804565\n",
      "Run 153 | Loss: 0.002693823305889964\n",
      "Run 154 | Loss: 0.0026906647253781557\n",
      "Run 155 | Loss: 0.00268756621517241\n",
      "Run 156 | Loss: 0.002684524515643716\n",
      "Run 157 | Loss: 0.0026815368328243494\n",
      "Run 158 | Loss: 0.002678600139915943\n",
      "Run 159 | Loss: 0.0026757156010717154\n",
      "Run 160 | Loss: 0.0026728734374046326\n",
      "Run 161 | Loss: 0.0026700887829065323\n",
      "Run 162 | Loss: 0.0026673488318920135\n",
      "Run 163 | Loss: 0.002664652420207858\n",
      "Run 164 | Loss: 0.0026620058342814445\n",
      "Run 165 | Loss: 0.002659399062395096\n",
      "Run 166 | Loss: 0.0026568362955003977\n",
      "Run 167 | Loss: 0.00265431753359735\n",
      "Run 168 | Loss: 0.002651832066476345\n",
      "Run 169 | Loss: 0.002649392932653427\n",
      "Run 170 | Loss: 0.0026469894219189882\n",
      "Run 171 | Loss: 0.0026446226984262466\n",
      "Run 172 | Loss: 0.002642296953126788\n",
      "Run 173 | Loss: 0.0026400021743029356\n",
      "Run 174 | Loss: 0.0026377455797046423\n",
      "Run 175 | Loss: 0.002635519951581955\n",
      "Run 176 | Loss: 0.0026333339046686888\n",
      "Run 177 | Loss: 0.0026311716064810753\n",
      "Run 178 | Loss: 0.0026290465611964464\n",
      "Run 179 | Loss: 0.0026269510854035616\n",
      "Run 180 | Loss: 0.002624883083626628\n",
      "Run 181 | Loss: 0.0026228500064462423\n",
      "Run 182 | Loss: 0.002620840445160866\n",
      "Run 183 | Loss: 0.0026188616175204515\n",
      "Run 184 | Loss: 0.002616911195218563\n",
      "Run 185 | Loss: 0.0026149863842874765\n",
      "Run 186 | Loss: 0.0026130888145416975\n",
      "Run 187 | Loss: 0.0026112154591828585\n",
      "Run 188 | Loss: 0.0026093723718076944\n",
      "Run 189 | Loss: 0.0026075446512550116\n",
      "Run 190 | Loss: 0.0026057518552988768\n",
      "Run 191 | Loss: 0.002603975823149085\n",
      "Run 192 | Loss: 0.0026022230740636587\n",
      "Run 193 | Loss: 0.002600496867671609\n",
      "Run 194 | Loss: 0.0025987892877310514\n",
      "Run 195 | Loss: 0.0025970975402742624\n",
      "Run 196 | Loss: 0.0025954365264624357\n",
      "Run 197 | Loss: 0.00259378575719893\n",
      "Run 198 | Loss: 0.0025921689812093973\n",
      "Run 199 | Loss: 0.0025905598886311054\n",
      "Run 200 | Loss: 0.002588976640254259\n",
      "Run 201 | Loss: 0.002587410854175687\n",
      "Run 202 | Loss: 0.002585864393040538\n",
      "Run 203 | Loss: 0.002584330504760146\n",
      "Run 204 | Loss: 0.0025828201323747635\n",
      "Run 205 | Loss: 0.002581322332844138\n",
      "Run 206 | Loss: 0.0025798503775149584\n",
      "Run 207 | Loss: 0.0025783905293792486\n",
      "Run 208 | Loss: 0.0025769437197595835\n",
      "Run 209 | Loss: 0.0025755143724381924\n",
      "Run 210 | Loss: 0.0025741036515682936\n",
      "Run 211 | Loss: 0.00257270154543221\n",
      "Run 212 | Loss: 0.002571321791037917\n",
      "Run 213 | Loss: 0.002569952979683876\n",
      "Run 214 | Loss: 0.002568600932136178\n",
      "Run 215 | Loss: 0.0025672621559351683\n",
      "Run 216 | Loss: 0.0025659375824034214\n",
      "Run 217 | Loss: 0.0025646218564361334\n",
      "Run 218 | Loss: 0.002563324524089694\n",
      "Run 219 | Loss: 0.002562042325735092\n",
      "Run 220 | Loss: 0.002560765715315938\n",
      "Run 221 | Loss: 0.0025595086626708508\n",
      "Run 222 | Loss: 0.0025582588277757168\n",
      "Run 223 | Loss: 0.002557023661211133\n",
      "Run 224 | Loss: 0.0025558050256222486\n",
      "Run 225 | Loss: 0.0025545901153236628\n",
      "Run 226 | Loss: 0.002553388476371765\n",
      "Run 227 | Loss: 0.002552200108766556\n",
      "Run 228 | Loss: 0.0025510236155241728\n",
      "Run 229 | Loss: 0.002549851080402732\n",
      "Run 230 | Loss: 0.002548698103055358\n",
      "Run 231 | Loss: 0.0025475502479821444\n",
      "Run 232 | Loss: 0.0025464172940701246\n",
      "Run 233 | Loss: 0.0025452866684645414\n",
      "Run 234 | Loss: 0.0025441725738346577\n",
      "Run 235 | Loss: 0.0025430647656321526\n",
      "Run 236 | Loss: 0.0025419644080102444\n",
      "Run 237 | Loss: 0.0025408773217350245\n",
      "Run 238 | Loss: 0.0025398002471774817\n",
      "Run 239 | Loss: 0.002538728527724743\n",
      "Run 240 | Loss: 0.002537672407925129\n",
      "Run 241 | Loss: 0.002536617685109377\n",
      "Run 242 | Loss: 0.0025355734396725893\n",
      "Run 243 | Loss: 0.0025345373433083296\n",
      "Run 244 | Loss: 0.002533513819798827\n",
      "Run 245 | Loss: 0.002532490761950612\n",
      "Run 246 | Loss: 0.002531479112803936\n",
      "Run 247 | Loss: 0.0025304779410362244\n",
      "Run 248 | Loss: 0.0025294809602200985\n",
      "Run 249 | Loss: 0.0025284914299845695\n",
      "Run 250 | Loss: 0.002527515636757016\n",
      "Run 251 | Loss: 0.002526538912206888\n",
      "Run 252 | Loss: 0.002525573829188943\n",
      "Run 253 | Loss: 0.0025246150325983763\n",
      "Run 254 | Loss: 0.0025236625224351883\n",
      "Run 255 | Loss: 0.002522715600207448\n",
      "Run 256 | Loss: 0.002521780552342534\n",
      "Run 257 | Loss: 0.002520844340324402\n",
      "Run 258 | Loss: 0.002519924659281969\n",
      "Run 259 | Loss: 0.00251900521107018\n",
      "Run 260 | Loss: 0.002518092282116413\n",
      "Run 261 | Loss: 0.002517182379961014\n",
      "Run 262 | Loss: 0.0025162852834910154\n",
      "Run 263 | Loss: 0.0025153912138193846\n",
      "Run 264 | Loss: 0.0025144973769783974\n",
      "Run 265 | Loss: 0.002513618441298604\n",
      "Run 266 | Loss: 0.002512742066755891\n",
      "Run 267 | Loss: 0.0025118673220276833\n",
      "Run 268 | Loss: 0.0025110035203397274\n",
      "Run 269 | Loss: 0.002510141348466277\n",
      "Run 270 | Loss: 0.002509289188310504\n",
      "Run 271 | Loss: 0.0025084365624934435\n",
      "Run 272 | Loss: 0.0025075890589505434\n",
      "Run 273 | Loss: 0.002506752498447895\n",
      "Run 274 | Loss: 0.002505918964743614\n",
      "Run 275 | Loss: 0.0025050851982086897\n",
      "Run 276 | Loss: 0.0025042628403753042\n",
      "Run 277 | Loss: 0.0025034460704773664\n",
      "Run 278 | Loss: 0.002502631861716509\n",
      "Run 279 | Loss: 0.002501818584278226\n",
      "Run 280 | Loss: 0.0025010094977915287\n",
      "Run 281 | Loss: 0.002500210190191865\n",
      "Run 282 | Loss: 0.0024994106497615576\n",
      "Run 283 | Loss: 0.002498621353879571\n",
      "Run 284 | Loss: 0.002497838344424963\n",
      "Run 285 | Loss: 0.0024970516096800566\n",
      "Run 286 | Loss: 0.0024962699972093105\n",
      "Run 287 | Loss: 0.002495492808520794\n",
      "Run 288 | Loss: 0.0024947242345660925\n",
      "Run 289 | Loss: 0.002493960550054908\n",
      "Run 290 | Loss: 0.0024931887164711952\n",
      "Run 291 | Loss: 0.0024924350436776876\n",
      "Run 292 | Loss: 0.0024916788097471\n",
      "Run 293 | Loss: 0.0024909244384616613\n",
      "Run 294 | Loss: 0.0024901768192648888\n",
      "Run 295 | Loss: 0.002489436650648713\n",
      "Run 296 | Loss: 0.0024886925239115953\n",
      "Run 297 | Loss: 0.0024879539851099253\n",
      "Run 298 | Loss: 0.0024872198700904846\n",
      "Run 299 | Loss: 0.002486494602635503\n",
      "Run 300 | Loss: 0.002485767239704728\n",
      "Run 301 | Loss: 0.002485044999048114\n",
      "Run 302 | Loss: 0.0024843227583914995\n",
      "Run 303 | Loss: 0.002483608201146126\n",
      "Run 304 | Loss: 0.002482891781255603\n",
      "Run 305 | Loss: 0.002482181414961815\n",
      "Run 306 | Loss: 0.002481478499248624\n",
      "Run 307 | Loss: 0.002480774652212858\n",
      "Run 308 | Loss: 0.0024800729006528854\n",
      "Run 309 | Loss: 0.0024793760385364294\n",
      "Run 310 | Loss: 0.002478678710758686\n",
      "Run 311 | Loss: 0.0024779902305454016\n",
      "Run 312 | Loss: 0.002477301051840186\n",
      "Run 313 | Loss: 0.002476616995409131\n",
      "Run 314 | Loss: 0.0024759324733167887\n",
      "Run 315 | Loss: 0.002475253539159894\n",
      "Run 316 | Loss: 0.0024745753034949303\n",
      "Run 317 | Loss: 0.002473898231983185\n",
      "Run 318 | Loss: 0.002473230008035898\n",
      "Run 319 | Loss: 0.002472560852766037\n",
      "Run 320 | Loss: 0.0024718944914638996\n",
      "Run 321 | Loss: 0.0024712327867746353\n",
      "Run 322 | Loss: 0.002470565726980567\n",
      "Run 323 | Loss: 0.0024699124041944742\n",
      "Run 324 | Loss: 0.002469257451593876\n",
      "Run 325 | Loss: 0.002468600170686841\n",
      "Run 326 | Loss: 0.0024679494090378284\n",
      "Run 327 | Loss: 0.0024673014413565397\n",
      "Run 328 | Loss: 0.002466655569151044\n",
      "Run 329 | Loss: 0.0024660094641149044\n",
      "Run 330 | Loss: 0.0024653717409819365\n",
      "Run 331 | Loss: 0.002464728197082877\n",
      "Run 332 | Loss: 0.002464093966409564\n",
      "Run 333 | Loss: 0.0024634625297039747\n",
      "Run 334 | Loss: 0.002462825970724225\n",
      "Run 335 | Loss: 0.002462197793647647\n",
      "Run 336 | Loss: 0.0024615696165710688\n",
      "Run 337 | Loss: 0.0024609428364783525\n",
      "Run 338 | Loss: 0.002460321644321084\n",
      "Run 339 | Loss: 0.002459699986502528\n",
      "Run 340 | Loss: 0.0024590755347162485\n",
      "Run 341 | Loss: 0.0024584669154137373\n",
      "Run 342 | Loss: 0.0024578471202403307\n",
      "Run 343 | Loss: 0.0024572378024458885\n",
      "Run 344 | Loss: 0.0024566221982240677\n",
      "Run 345 | Loss: 0.0024560138117522\n",
      "Run 346 | Loss: 0.0024554054252803326\n",
      "Run 347 | Loss: 0.002454805886372924\n",
      "Run 348 | Loss: 0.0024541968014091253\n",
      "Run 349 | Loss: 0.002453595632687211\n",
      "Run 350 | Loss: 0.002452993066981435\n",
      "Run 351 | Loss: 0.0024523960892111063\n",
      "Run 352 | Loss: 0.002451803768053651\n",
      "Run 353 | Loss: 0.002451204461976886\n",
      "Run 354 | Loss: 0.0024506160989403725\n",
      "Run 355 | Loss: 0.002450026338919997\n",
      "Run 356 | Loss: 0.0024494354147464037\n",
      "Run 357 | Loss: 0.002448850777000189\n",
      "Run 358 | Loss: 0.002448262646794319\n",
      "Run 359 | Loss: 0.0024476812686771154\n",
      "Run 360 | Loss: 0.002447101753205061\n",
      "Run 361 | Loss: 0.0024465203750878572\n",
      "Run 362 | Loss: 0.0024459364358335733\n",
      "Run 363 | Loss: 0.00244536274112761\n",
      "Run 364 | Loss: 0.0024447881150990725\n",
      "Run 365 | Loss: 0.0024442144203931093\n",
      "Run 366 | Loss: 0.002443639561533928\n",
      "Run 367 | Loss: 0.002443073084577918\n",
      "Run 368 | Loss: 0.0024425035808235407\n",
      "Run 369 | Loss: 0.002441933611407876\n",
      "Run 370 | Loss: 0.002441365271806717\n",
      "Run 371 | Loss: 0.002440802287310362\n",
      "Run 372 | Loss: 0.002440236508846283\n",
      "Run 373 | Loss: 0.0024396793451160192\n",
      "Run 374 | Loss: 0.0024391149636358023\n",
      "Run 375 | Loss: 0.0024385543074458838\n",
      "Run 376 | Loss: 0.002438001334667206\n",
      "Run 377 | Loss: 0.0024374432396143675\n",
      "Run 378 | Loss: 0.002436888637021184\n",
      "Run 379 | Loss: 0.0024363379925489426\n",
      "Run 380 | Loss: 0.002435786882415414\n",
      "Run 381 | Loss: 0.0024352348409593105\n",
      "Run 382 | Loss: 0.0024346860591322184\n",
      "Run 383 | Loss: 0.002434137975797057\n",
      "Run 384 | Loss: 0.002433591289445758\n",
      "Run 385 | Loss: 0.0024330492597073317\n",
      "Run 386 | Loss: 0.0024325011763721704\n",
      "Run 387 | Loss: 0.0024319624062627554\n",
      "Run 388 | Loss: 0.0024314187467098236\n",
      "Run 389 | Loss: 0.0024308788124471903\n",
      "Run 390 | Loss: 0.0024303391110152006\n",
      "Run 391 | Loss: 0.002429800108075142\n",
      "Run 392 | Loss: 0.0024292657617479563\n",
      "Run 393 | Loss: 0.002428729087114334\n",
      "Run 394 | Loss: 0.0024281926453113556\n",
      "Run 395 | Loss: 0.0024276627227663994\n",
      "Run 396 | Loss: 0.0024271353613585234\n",
      "Run 397 | Loss: 0.0024266038089990616\n",
      "Run 398 | Loss: 0.0024260717909783125\n",
      "Run 399 | Loss: 0.002425543265417218\n",
      "Run 400 | Loss: 0.0024250205606222153\n",
      "Run 401 | Loss: 0.002424493432044983\n",
      "Run 402 | Loss: 0.002423967467620969\n",
      "Run 403 | Loss: 0.0024234422016888857\n",
      "Run 404 | Loss: 0.002422922058030963\n",
      "Run 405 | Loss: 0.002422398654744029\n",
      "Run 406 | Loss: 0.0024218799080699682\n",
      "Run 407 | Loss: 0.0024213597644120455\n",
      "Run 408 | Loss: 0.002420843346044421\n",
      "Run 409 | Loss: 0.0024203297216445208\n",
      "Run 410 | Loss: 0.0024198119062930346\n",
      "Run 411 | Loss: 0.002419294323772192\n",
      "Run 412 | Loss: 0.0024187832605093718\n",
      "Run 413 | Loss: 0.002418267773464322\n",
      "Run 414 | Loss: 0.002417757175862789\n",
      "Run 415 | Loss: 0.002417247975245118\n",
      "Run 416 | Loss: 0.0024167357478290796\n",
      "Run 417 | Loss: 0.002416228177025914\n",
      "Run 418 | Loss: 0.0024157206062227488\n",
      "Run 419 | Loss: 0.002415213268250227\n",
      "Run 420 | Loss: 0.00241470686160028\n",
      "Run 421 | Loss: 0.0024142013862729073\n",
      "Run 422 | Loss: 0.0024136987049132586\n",
      "Run 423 | Loss: 0.0024131927639245987\n",
      "Run 424 | Loss: 0.002412693342193961\n",
      "Run 425 | Loss: 0.002412190428003669\n",
      "Run 426 | Loss: 0.0024116903077811003\n",
      "Run 427 | Loss: 0.002411195309832692\n",
      "Run 428 | Loss: 0.0024106933269649744\n",
      "Run 429 | Loss: 0.0024101960007101297\n",
      "Run 430 | Loss: 0.0024097030982375145\n",
      "Run 431 | Loss: 0.002409200882539153\n",
      "Run 432 | Loss: 0.0024087110068649054\n",
      "Run 433 | Loss: 0.0024082153104245663\n",
      "Run 434 | Loss: 0.0024077214766293764\n",
      "Run 435 | Loss: 0.0024072316009551287\n",
      "Run 436 | Loss: 0.0024067400954663754\n",
      "Run 437 | Loss: 0.0024062469601631165\n",
      "Run 438 | Loss: 0.002405756851658225\n",
      "Run 439 | Loss: 0.002405265811830759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 440 | Loss: 0.0024047805927693844\n",
      "Run 441 | Loss: 0.002404293976724148\n",
      "Run 442 | Loss: 0.002403806196525693\n",
      "Run 443 | Loss: 0.00240332237444818\n",
      "Run 444 | Loss: 0.002402838785201311\n",
      "Run 445 | Loss: 0.002402356592938304\n",
      "Run 446 | Loss: 0.002401870209723711\n",
      "Run 447 | Loss: 0.0024013889487832785\n",
      "Run 448 | Loss: 0.0024009074550122023\n",
      "Run 449 | Loss: 0.0024004296865314245\n",
      "Run 450 | Loss: 0.0023999481927603483\n",
      "Run 451 | Loss: 0.002399470191448927\n",
      "Run 452 | Loss: 0.0023989903274923563\n",
      "Run 453 | Loss: 0.0023985158186405897\n",
      "Run 454 | Loss: 0.0023980361875146627\n",
      "Run 455 | Loss: 0.002397557720541954\n",
      "Run 456 | Loss: 0.002397084841504693\n",
      "Run 457 | Loss: 0.0023966103326529264\n",
      "Run 458 | Loss: 0.0023961400147527456\n",
      "Run 459 | Loss: 0.002395669696852565\n",
      "Run 460 | Loss: 0.0023951937910169363\n",
      "Run 461 | Loss: 0.002394717186689377\n",
      "Run 462 | Loss: 0.002394249429926276\n",
      "Run 463 | Loss: 0.0023937809746712446\n",
      "Run 464 | Loss: 0.0023933094926178455\n",
      "Run 465 | Loss: 0.0023928415030241013\n",
      "Run 466 | Loss: 0.002392376074567437\n",
      "Run 467 | Loss: 0.002391906687989831\n",
      "Run 468 | Loss: 0.002391434507444501\n",
      "Run 469 | Loss: 0.002390974434092641\n",
      "Run 470 | Loss: 0.002390505513176322\n",
      "Run 471 | Loss: 0.0023900463711470366\n",
      "Run 472 | Loss: 0.0023895795457065105\n",
      "Run 473 | Loss: 0.0023891187738627195\n",
      "Run 474 | Loss: 0.00238865171559155\n",
      "Run 475 | Loss: 0.0023881930392235518\n",
      "Run 476 | Loss: 0.0023877338971942663\n",
      "Run 477 | Loss: 0.002387269167229533\n",
      "Run 478 | Loss: 0.0023868121206760406\n",
      "Run 479 | Loss: 0.002386350417509675\n",
      "Run 480 | Loss: 0.0023858945351094007\n",
      "Run 481 | Loss: 0.0023854339960962534\n",
      "Run 482 | Loss: 0.002384977648034692\n",
      "Run 483 | Loss: 0.002384519437327981\n",
      "Run 484 | Loss: 0.0023840698413550854\n",
      "Run 485 | Loss: 0.002383608603850007\n",
      "Run 486 | Loss: 0.002383157843723893\n",
      "Run 487 | Loss: 0.00238270522095263\n",
      "Run 488 | Loss: 0.002382249804213643\n",
      "Run 489 | Loss: 0.0023817953187972307\n",
      "Run 490 | Loss: 0.0023813459556549788\n",
      "Run 491 | Loss: 0.0023808905389159918\n",
      "Run 492 | Loss: 0.002380441641435027\n",
      "Run 493 | Loss: 0.002379992278292775\n",
      "Run 494 | Loss: 0.0023795422166585922\n",
      "Run 495 | Loss: 0.0023790907580405474\n",
      "Run 496 | Loss: 0.002378645585849881\n",
      "Run 497 | Loss: 0.0023781952913850546\n",
      "Run 498 | Loss: 0.0023777512833476067\n",
      "Run 499 | Loss: 0.0023773033171892166\n",
      "Run 500 | Loss: 0.0023768586106598377\n",
      "Run 501 | Loss: 0.0023764108773320913\n",
      "Run 502 | Loss: 0.0023759675677865744\n",
      "Run 503 | Loss: 0.002375519834458828\n",
      "Run 504 | Loss: 0.0023750769905745983\n",
      "Run 505 | Loss: 0.002374635310843587\n",
      "Run 506 | Loss: 0.0023741901386529207\n",
      "Run 507 | Loss: 0.0023737510200589895\n",
      "Run 508 | Loss: 0.002373308641836047\n",
      "Run 509 | Loss: 0.002372863469645381\n",
      "Run 510 | Loss: 0.002372426213696599\n",
      "Run 511 | Loss: 0.002371986862272024\n",
      "Run 512 | Loss: 0.002371549839153886\n",
      "Run 513 | Loss: 0.002371106529608369\n",
      "Run 514 | Loss: 0.0023706674110144377\n",
      "Run 515 | Loss: 0.0023702308535575867\n",
      "Run 516 | Loss: 0.002369796158745885\n",
      "Run 517 | Loss: 0.002369354944676161\n",
      "Run 518 | Loss: 0.002368924207985401\n",
      "Run 519 | Loss: 0.0023684860207140446\n",
      "Run 520 | Loss: 0.00236805179156363\n",
      "Run 521 | Loss: 0.0023676175624132156\n",
      "Run 522 | Loss: 0.0023671819362789392\n",
      "Run 523 | Loss: 0.0023667479399591684\n",
      "Run 524 | Loss: 0.002366315806284547\n",
      "Run 525 | Loss: 0.002365881809964776\n",
      "Run 526 | Loss: 0.002365450607612729\n",
      "Run 527 | Loss: 0.0023650217335671186\n",
      "Run 528 | Loss: 0.0023645914625376463\n",
      "Run 529 | Loss: 0.002364162588492036\n",
      "Run 530 | Loss: 0.0023637288250029087\n",
      "Run 531 | Loss: 0.002363297389820218\n",
      "Run 532 | Loss: 0.002362871542572975\n",
      "Run 533 | Loss: 0.002362443134188652\n",
      "Run 534 | Loss: 0.0023620144929736853\n",
      "Run 535 | Loss: 0.0023615898098796606\n",
      "Run 536 | Loss: 0.0023611602373421192\n",
      "Run 537 | Loss: 0.002360737882554531\n",
      "Run 538 | Loss: 0.002360310172662139\n",
      "Run 539 | Loss: 0.0023598840925842524\n",
      "Run 540 | Loss: 0.002359457779675722\n",
      "Run 541 | Loss: 0.002359036123380065\n",
      "Run 542 | Loss: 0.002358607714995742\n",
      "Run 543 | Loss: 0.0023581895511597395\n",
      "Run 544 | Loss: 0.002357762772589922\n",
      "Run 545 | Loss: 0.002357344375923276\n",
      "Run 546 | Loss: 0.0023569187615066767\n",
      "Run 547 | Loss: 0.002356502925977111\n",
      "Run 548 | Loss: 0.0023560794070363045\n",
      "Run 549 | Loss: 0.00235565728507936\n",
      "Run 550 | Loss: 0.0023552370257675648\n",
      "Run 551 | Loss: 0.0023548209574073553\n",
      "Run 552 | Loss: 0.0023543972056359053\n",
      "Run 553 | Loss: 0.0023539832327514887\n",
      "Run 554 | Loss: 0.002353567397221923\n",
      "Run 555 | Loss: 0.002353143645450473\n",
      "Run 556 | Loss: 0.002352725714445114\n",
      "Run 557 | Loss: 0.0023523105774074793\n",
      "Run 558 | Loss: 0.00235189707018435\n",
      "Run 559 | Loss: 0.002351482165977359\n",
      "Run 560 | Loss: 0.002351064933463931\n",
      "Run 561 | Loss: 0.0023506488651037216\n",
      "Run 562 | Loss: 0.0023502372205257416\n",
      "Run 563 | Loss: 0.002349820686504245\n",
      "Run 564 | Loss: 0.002349406247958541\n",
      "Run 565 | Loss: 0.0023489955347031355\n",
      "Run 566 | Loss: 0.0023485843557864428\n",
      "Run 567 | Loss: 0.0023481708485633135\n",
      "Run 568 | Loss: 0.0023477596696466208\n",
      "Run 569 | Loss: 0.002347349189221859\n",
      "Run 570 | Loss: 0.0023469373118132353\n",
      "Run 571 | Loss: 0.0023465242702513933\n",
      "Run 572 | Loss: 0.0023461123928427696\n",
      "Run 573 | Loss: 0.002345705172047019\n",
      "Run 574 | Loss: 0.0023452972527593374\n",
      "Run 575 | Loss: 0.0023448846768587828\n",
      "Run 576 | Loss: 0.002344477688893676\n",
      "Run 577 | Loss: 0.002344071166589856\n",
      "Run 578 | Loss: 0.00234366487711668\n",
      "Run 579 | Loss: 0.0023432534653693438\n",
      "Run 580 | Loss: 0.0023428492713719606\n",
      "Run 581 | Loss: 0.0023424429818987846\n",
      "Run 582 | Loss: 0.0023420427460223436\n",
      "Run 583 | Loss: 0.002341633662581444\n",
      "Run 584 | Loss: 0.002341232495382428\n",
      "Run 585 | Loss: 0.002340824343264103\n",
      "Run 586 | Loss: 0.002340418752282858\n",
      "Run 587 | Loss: 0.002340016420930624\n",
      "Run 588 | Loss: 0.0023396110627800226\n",
      "Run 589 | Loss: 0.0023392103612422943\n",
      "Run 590 | Loss: 0.002338808262720704\n",
      "Run 591 | Loss: 0.0023384063970297575\n",
      "Run 592 | Loss: 0.0023380040656775236\n",
      "Run 593 | Loss: 0.0023376026656478643\n",
      "Run 594 | Loss: 0.002337203361093998\n",
      "Run 595 | Loss: 0.0023368021938949823\n",
      "Run 596 | Loss: 0.0023364052176475525\n",
      "Run 597 | Loss: 0.002336004050448537\n",
      "Run 598 | Loss: 0.002335601719096303\n",
      "Run 599 | Loss: 0.002335203345865011\n",
      "Run 600 | Loss: 0.0023348010145127773\n",
      "Run 601 | Loss: 0.002334409160539508\n",
      "Run 602 | Loss: 0.002334009623154998\n",
      "Run 603 | Loss: 0.0023336149752140045\n",
      "Run 604 | Loss: 0.002333215204998851\n",
      "Run 605 | Loss: 0.0023328198585659266\n",
      "Run 606 | Loss: 0.0023324270732700825\n",
      "Run 607 | Loss: 0.00233203312382102\n",
      "Run 608 | Loss: 0.002331632887944579\n",
      "Run 609 | Loss: 0.002331239404156804\n",
      "Run 610 | Loss: 0.0023308477830141783\n",
      "Run 611 | Loss: 0.0023304512724280357\n",
      "Run 612 | Loss: 0.002330056158825755\n",
      "Run 613 | Loss: 0.00232966267503798\n",
      "Run 614 | Loss: 0.0023292694240808487\n",
      "Run 615 | Loss: 0.0023288833908736706\n",
      "Run 616 | Loss: 0.002328490372747183\n",
      "Run 617 | Loss: 0.0023280964232981205\n",
      "Run 618 | Loss: 0.0023277029395103455\n",
      "Run 619 | Loss: 0.0023273152764886618\n",
      "Run 620 | Loss: 0.0023269241210073233\n",
      "Run 621 | Loss: 0.002326534129679203\n",
      "Run 622 | Loss: 0.0023261429741978645\n",
      "Run 623 | Loss: 0.002325755078345537\n",
      "Run 624 | Loss: 0.0023253655526787043\n",
      "Run 625 | Loss: 0.002324974164366722\n",
      "Run 626 | Loss: 0.0023245869670063257\n",
      "Run 627 | Loss: 0.0023242002353072166\n",
      "Run 628 | Loss: 0.002323814434930682\n",
      "Run 629 | Loss: 0.002323425142094493\n",
      "Run 630 | Loss: 0.0023230407387018204\n",
      "Run 631 | Loss: 0.0023226551711559296\n",
      "Run 632 | Loss: 0.002322266111150384\n",
      "Run 633 | Loss: 0.0023218821734189987\n",
      "Run 634 | Loss: 0.0023214935790747404\n",
      "Run 635 | Loss: 0.00232111313380301\n",
      "Run 636 | Loss: 0.00232072826474905\n",
      "Run 637 | Loss: 0.0023203447926789522\n",
      "Run 638 | Loss: 0.0023199606221169233\n",
      "Run 639 | Loss: 0.002319575287401676\n",
      "Run 640 | Loss: 0.002319194609299302\n",
      "Run 641 | Loss: 0.002318811370059848\n",
      "Run 642 | Loss: 0.002318429993465543\n",
      "Run 643 | Loss: 0.00231804302893579\n",
      "Run 644 | Loss: 0.002317665610462427\n",
      "Run 645 | Loss: 0.0023172844666987658\n",
      "Run 646 | Loss: 0.002316904254257679\n",
      "Run 647 | Loss: 0.002316528232768178\n",
      "Run 648 | Loss: 0.0023161384742707014\n",
      "Run 649 | Loss: 0.0023157591931521893\n",
      "Run 650 | Loss: 0.0023153829388320446\n",
      "Run 651 | Loss: 0.0023150022607296705\n",
      "Run 652 | Loss: 0.0023146220482885838\n",
      "Run 653 | Loss: 0.0023142455611377954\n",
      "Run 654 | Loss: 0.002313872566446662\n",
      "Run 655 | Loss: 0.002313492354005575\n",
      "Run 656 | Loss: 0.0023131154011934996\n",
      "Run 657 | Loss: 0.002312738448381424\n",
      "Run 658 | Loss: 0.002312358235940337\n",
      "Run 659 | Loss: 0.0023119875695556402\n",
      "Run 660 | Loss: 0.0023116092197597027\n",
      "Run 661 | Loss: 0.0023112355265766382\n",
      "Run 662 | Loss: 0.002310858340933919\n",
      "Run 663 | Loss: 0.0023104813881218433\n",
      "Run 664 | Loss: 0.0023101104889065027\n",
      "Run 665 | Loss: 0.00230973307043314\n",
      "Run 666 | Loss: 0.0023093586787581444\n",
      "Run 667 | Loss: 0.002308988245204091\n",
      "Run 668 | Loss: 0.002308617113158107\n",
      "Run 669 | Loss: 0.0023082380648702383\n",
      "Run 670 | Loss: 0.002307866932824254\n",
      "Run 671 | Loss: 0.0023074967321008444\n",
      "Run 672 | Loss: 0.002307121641933918\n",
      "Run 673 | Loss: 0.0023067547008395195\n",
      "Run 674 | Loss: 0.0023063807748258114\n",
      "Run 675 | Loss: 0.002306010341271758\n",
      "Run 676 | Loss: 0.002305641071870923\n",
      "Run 677 | Loss: 0.0023052729666233063\n",
      "Run 678 | Loss: 0.0023049027658998966\n",
      "Run 679 | Loss: 0.002304532565176487\n",
      "Run 680 | Loss: 0.00230416189879179\n",
      "Run 681 | Loss: 0.002303791930899024\n",
      "Run 682 | Loss: 0.002303424524143338\n",
      "Run 683 | Loss: 0.0023030575830489397\n",
      "Run 684 | Loss: 0.002302690641954541\n",
      "Run 685 | Loss: 0.002302320674061775\n",
      "Run 686 | Loss: 0.002301956759765744\n",
      "Run 687 | Loss: 0.0023015898186713457\n",
      "Run 688 | Loss: 0.00230122497305274\n",
      "Run 689 | Loss: 0.0023008554708212614\n",
      "Run 690 | Loss: 0.0023004894610494375\n",
      "Run 691 | Loss: 0.0023001229856163263\n",
      "Run 692 | Loss: 0.002299761399626732\n",
      "Run 693 | Loss: 0.0022993949241936207\n",
      "Run 694 | Loss: 0.0022990317083895206\n",
      "Run 695 | Loss: 0.0022986705880612135\n",
      "Run 696 | Loss: 0.0022983048111200333\n",
      "Run 697 | Loss: 0.002297937637194991\n",
      "Run 698 | Loss: 0.0022975767496973276\n",
      "Run 699 | Loss: 0.002297215163707733\n",
      "Run 700 | Loss: 0.0022968545090407133\n",
      "Run 701 | Loss: 0.0022964912932366133\n",
      "Run 702 | Loss: 0.002296124817803502\n",
      "Run 703 | Loss: 0.002295764395967126\n",
      "Run 704 | Loss: 0.0022954049054533243\n",
      "Run 705 | Loss: 0.002295047277584672\n",
      "Run 706 | Loss: 0.0022946870885789394\n",
      "Run 707 | Loss: 0.0022943250369280577\n",
      "Run 708 | Loss: 0.0022939618211239576\n",
      "Run 709 | Loss: 0.00229360512457788\n",
      "Run 710 | Loss: 0.0022932449355721474\n",
      "Run 711 | Loss: 0.002292884746566415\n",
      "Run 712 | Loss: 0.0022925236262381077\n",
      "Run 713 | Loss: 0.00229216949082911\n",
      "Run 714 | Loss: 0.0022918100003153086\n",
      "Run 715 | Loss: 0.002291455864906311\n",
      "Run 716 | Loss: 0.0022910963743925095\n",
      "Run 717 | Loss: 0.002290735486894846\n",
      "Run 718 | Loss: 0.002290383679792285\n",
      "Run 719 | Loss: 0.0022900213953107595\n",
      "Run 720 | Loss: 0.002289670752361417\n",
      "Run 721 | Loss: 0.0022893131244927645\n",
      "Run 722 | Loss: 0.002288958989083767\n",
      "Run 723 | Loss: 0.00228860299102962\n",
      "Run 724 | Loss: 0.002288246527314186\n",
      "Run 725 | Loss: 0.0022878944873809814\n",
      "Run 726 | Loss: 0.002287535695359111\n",
      "Run 727 | Loss: 0.0022871848195791245\n",
      "Run 728 | Loss: 0.0022868302185088396\n",
      "Run 729 | Loss: 0.0022864793427288532\n",
      "Run 730 | Loss: 0.00228612101636827\n",
      "Run 731 | Loss: 0.002285771770402789\n",
      "Run 732 | Loss: 0.00228541879914701\n",
      "Run 733 | Loss: 0.0022850690875202417\n",
      "Run 734 | Loss: 0.0022847142536193132\n",
      "Run 735 | Loss: 0.002284366637468338\n",
      "Run 736 | Loss: 0.0022840159945189953\n",
      "Run 737 | Loss: 0.0022836660500615835\n",
      "Run 738 | Loss: 0.0022833130788058043\n",
      "Run 739 | Loss: 0.002282961504533887\n",
      "Run 740 | Loss: 0.0022826113272458315\n",
      "Run 741 | Loss: 0.002282261149957776\n",
      "Run 742 | Loss: 0.002281914697960019\n",
      "Run 743 | Loss: 0.002281560329720378\n",
      "Run 744 | Loss: 0.0022812134120613337\n",
      "Run 745 | Loss: 0.0022808678913861513\n",
      "Run 746 | Loss: 0.002280519111081958\n",
      "Run 747 | Loss: 0.0022801707964390516\n",
      "Run 748 | Loss: 0.0022798217833042145\n",
      "Run 749 | Loss: 0.002279476495459676\n",
      "Run 750 | Loss: 0.0022791295778006315\n",
      "Run 751 | Loss: 0.0022787845227867365\n",
      "Run 752 | Loss: 0.0022784355096518993\n",
      "Run 753 | Loss: 0.0022780911531299353\n",
      "Run 754 | Loss: 0.0022777451667934656\n",
      "Run 755 | Loss: 0.0022773996461182833\n",
      "Run 756 | Loss: 0.002277052728459239\n",
      "Run 757 | Loss: 0.002276712330058217\n",
      "Run 758 | Loss: 0.0022763616871088743\n",
      "Run 759 | Loss: 0.002276016166433692\n",
      "Run 760 | Loss: 0.0022756746038794518\n",
      "Run 761 | Loss: 0.0022753330413252115\n",
      "Run 762 | Loss: 0.0022749847266823053\n",
      "Run 763 | Loss: 0.0022746436297893524\n",
      "Run 764 | Loss: 0.0022743032313883305\n",
      "Run 765 | Loss: 0.002273961203172803\n",
      "Run 766 | Loss: 0.0022736152168363333\n",
      "Run 767 | Loss: 0.002273273654282093\n",
      "Run 768 | Loss: 0.002272931160405278\n",
      "Run 769 | Loss: 0.002272592857480049\n",
      "Run 770 | Loss: 0.002272251294925809\n",
      "Run 771 | Loss: 0.002271912759169936\n",
      "Run 772 | Loss: 0.0022715714294463396\n",
      "Run 773 | Loss: 0.0022712303325533867\n",
      "Run 774 | Loss: 0.0022708887699991465\n",
      "Run 775 | Loss: 0.002270553493872285\n",
      "Run 776 | Loss: 0.0022702098358422518\n",
      "Run 777 | Loss: 0.002269869204610586\n",
      "Run 778 | Loss: 0.002269533695653081\n",
      "Run 779 | Loss: 0.002269194694235921\n",
      "Run 780 | Loss: 0.0022688547614961863\n",
      "Run 781 | Loss: 0.0022685176227241755\n",
      "Run 782 | Loss: 0.00226817955262959\n",
      "Run 783 | Loss: 0.0022678442765027285\n",
      "Run 784 | Loss: 0.002267509000375867\n",
      "Run 785 | Loss: 0.002267171861603856\n",
      "Run 786 | Loss: 0.002266831463202834\n",
      "Run 787 | Loss: 0.0022664933931082487\n",
      "Run 788 | Loss: 0.002266162307932973\n",
      "Run 789 | Loss: 0.002265821909531951\n",
      "Run 790 | Loss: 0.0022654866334050894\n",
      "Run 791 | Loss: 0.00226515531539917\n",
      "Run 792 | Loss: 0.00226481887511909\n",
      "Run 793 | Loss: 0.002264487324282527\n",
      "Run 794 | Loss: 0.002264150185510516\n",
      "Run 795 | Loss: 0.0022638137452304363\n",
      "Run 796 | Loss: 0.002263482427224517\n",
      "Run 797 | Loss: 0.0022631490137428045\n",
      "Run 798 | Loss: 0.0022628142032772303\n",
      "Run 799 | Loss: 0.0022624838165938854\n",
      "Run 800 | Loss: 0.0022621466778218746\n",
      "Run 801 | Loss: 0.0022618190851062536\n",
      "Run 802 | Loss: 0.002261483110487461\n",
      "Run 803 | Loss: 0.0022611517924815416\n",
      "Run 804 | Loss: 0.0022608241997659206\n",
      "Run 805 | Loss: 0.002260493114590645\n",
      "Run 806 | Loss: 0.002260160632431507\n",
      "Run 807 | Loss: 0.0022598293144255877\n",
      "Run 808 | Loss: 0.0022595024202018976\n",
      "Run 809 | Loss: 0.0022591715678572655\n",
      "Run 810 | Loss: 0.002258843509480357\n",
      "Run 811 | Loss: 0.0022585110273212194\n",
      "Run 812 | Loss: 0.002258183667436242\n",
      "Run 813 | Loss: 0.0022578551433980465\n",
      "Run 814 | Loss: 0.0022575233597308397\n",
      "Run 815 | Loss: 0.0022571953013539314\n",
      "Run 816 | Loss: 0.0022568681742995977\n",
      "Run 817 | Loss: 0.002256540348753333\n",
      "Run 818 | Loss: 0.0022562129888683558\n",
      "Run 819 | Loss: 0.0022558860946446657\n",
      "Run 820 | Loss: 0.002255558967590332\n",
      "Run 821 | Loss: 0.0022552325390279293\n",
      "Run 822 | Loss: 0.00225490122102201\n",
      "Run 823 | Loss: 0.0022545773535966873\n",
      "Run 824 | Loss: 0.002254250692203641\n",
      "Run 825 | Loss: 0.0022539240308105946\n",
      "Run 826 | Loss: 0.0022536038886755705\n",
      "Run 827 | Loss: 0.0022532744333148003\n",
      "Run 828 | Loss: 0.002252951031550765\n",
      "Run 829 | Loss: 0.0022526246029883623\n",
      "Run 830 | Loss: 0.0022522981744259596\n",
      "Run 831 | Loss: 0.002251978265121579\n",
      "Run 832 | Loss: 0.0022516523022204638\n",
      "Run 833 | Loss: 0.0022513263393193483\n",
      "Run 834 | Loss: 0.0022510087583214045\n",
      "Run 835 | Loss: 0.0022506832610815763\n",
      "Run 836 | Loss: 0.0022503600921481848\n",
      "Run 837 | Loss: 0.002250037854537368\n",
      "Run 838 | Loss: 0.0022497151512652636\n",
      "Run 839 | Loss: 0.0022493924479931593\n",
      "Run 840 | Loss: 0.002249073935672641\n",
      "Run 841 | Loss: 0.0022487484384328127\n",
      "Run 842 | Loss: 0.0022484303917735815\n",
      "Run 843 | Loss: 0.0022481062915176153\n",
      "Run 844 | Loss: 0.0022477854508906603\n",
      "Run 845 | Loss: 0.0022474625147879124\n",
      "Run 846 | Loss: 0.0022471442352980375\n",
      "Run 847 | Loss: 0.0022468266543000937\n",
      "Run 848 | Loss: 0.0022465030197054148\n",
      "Run 849 | Loss: 0.0022461856715381145\n",
      "Run 850 | Loss: 0.0022458722814917564\n",
      "Run 851 | Loss: 0.002245550276711583\n",
      "Run 852 | Loss: 0.0022452285047620535\n",
      "Run 853 | Loss: 0.002244912553578615\n",
      "Run 854 | Loss: 0.002244596602395177\n",
      "Run 855 | Loss: 0.0022442780900746584\n",
      "Run 856 | Loss: 0.0022439593449234962\n",
      "Run 857 | Loss: 0.0022436408326029778\n",
      "Run 858 | Loss: 0.002243325114250183\n",
      "Run 859 | Loss: 0.0022430066019296646\n",
      "Run 860 | Loss: 0.002242692746222019\n",
      "Run 861 | Loss: 0.002242371905595064\n",
      "Run 862 | Loss: 0.002242056420072913\n",
      "Run 863 | Loss: 0.002241741167381406\n",
      "Run 864 | Loss: 0.0022414273116737604\n",
      "Run 865 | Loss: 0.002241116249933839\n",
      "Run 866 | Loss: 0.002240797271952033\n",
      "Run 867 | Loss: 0.0022404794581234455\n",
      "Run 868 | Loss: 0.002240167697891593\n",
      "Run 869 | Loss: 0.0022398524452000856\n",
      "Run 870 | Loss: 0.0022395376581698656\n",
      "Run 871 | Loss: 0.002239224733784795\n",
      "Run 872 | Loss: 0.0022389101795852184\n",
      "Run 873 | Loss: 0.0022386012133210897\n",
      "Run 874 | Loss: 0.0022382880561053753\n",
      "Run 875 | Loss: 0.002237974898889661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 876 | Loss: 0.0022376608103513718\n",
      "Run 877 | Loss: 0.0022373495157808065\n",
      "Run 878 | Loss: 0.0022370354272425175\n",
      "Run 879 | Loss: 0.0022367227356880903\n",
      "Run 880 | Loss: 0.0022364144679158926\n",
      "Run 881 | Loss: 0.002236103406175971\n",
      "Run 882 | Loss: 0.00223578792065382\n",
      "Run 883 | Loss: 0.0022354822140187025\n",
      "Run 884 | Loss: 0.002235168358311057\n",
      "Run 885 | Loss: 0.0022348647471517324\n",
      "Run 886 | Loss: 0.002234550891444087\n",
      "Run 887 | Loss: 0.0022342405281960964\n",
      "Run 888 | Loss: 0.0022339324932545424\n",
      "Run 889 | Loss: 0.00223362073302269\n",
      "Run 890 | Loss: 0.002233315259218216\n",
      "Run 891 | Loss: 0.0022330048959702253\n",
      "Run 892 | Loss: 0.002232697093859315\n",
      "Run 893 | Loss: 0.002232382772490382\n",
      "Run 894 | Loss: 0.0022320812568068504\n",
      "Run 895 | Loss: 0.0022317685652524233\n",
      "Run 896 | Loss: 0.0022314644884318113\n",
      "Run 897 | Loss: 0.0022311604116111994\n",
      "Run 898 | Loss: 0.002230851911008358\n",
      "Run 899 | Loss: 0.0022305448073893785\n",
      "Run 900 | Loss: 0.0022302367724478245\n",
      "Run 901 | Loss: 0.0022299299016594887\n",
      "Run 902 | Loss: 0.002229624893516302\n",
      "Run 903 | Loss: 0.0022293198853731155\n",
      "Run 904 | Loss: 0.0022290132474154234\n",
      "Run 905 | Loss: 0.002228708239272237\n",
      "Run 906 | Loss: 0.0022284043952822685\n",
      "Run 907 | Loss: 0.002228100085631013\n",
      "Run 908 | Loss: 0.0022277964744716883\n",
      "Run 909 | Loss: 0.0022274889051914215\n",
      "Run 910 | Loss: 0.002227185294032097\n",
      "Run 911 | Loss: 0.002226881217211485\n",
      "Run 912 | Loss: 0.002226579701527953\n",
      "Run 913 | Loss: 0.002226275159046054\n",
      "Run 914 | Loss: 0.002225975040346384\n",
      "Run 915 | Loss: 0.0022256681695580482\n",
      "Run 916 | Loss: 0.0022253708448261023\n",
      "Run 917 | Loss: 0.0022250665351748466\n",
      "Run 918 | Loss: 0.002224762924015522\n",
      "Run 919 | Loss: 0.0022244590800255537\n",
      "Run 920 | Loss: 0.002224161522462964\n",
      "Run 921 | Loss: 0.0022238579113036394\n",
      "Run 922 | Loss: 0.0022235603537410498\n",
      "Run 923 | Loss: 0.00222325068898499\n",
      "Run 924 | Loss: 0.002222949406132102\n",
      "Run 925 | Loss: 0.0022226544097065926\n",
      "Run 926 | Loss: 0.0022223538253456354\n",
      "Run 927 | Loss: 0.002222053473815322\n",
      "Run 928 | Loss: 0.002221752656623721\n",
      "Run 929 | Loss: 0.002221455564722419\n",
      "Run 930 | Loss: 0.002221159404143691\n",
      "Run 931 | Loss: 0.0022208562586456537\n",
      "Run 932 | Loss: 0.0022205559071153402\n",
      "Run 933 | Loss: 0.0022202583495527506\n",
      "Run 934 | Loss: 0.0022199589293450117\n",
      "Run 935 | Loss: 0.0022196585778146982\n",
      "Run 936 | Loss: 0.0022193666081875563\n",
      "Run 937 | Loss: 0.0022190662566572428\n",
      "Run 938 | Loss: 0.002218768931925297\n",
      "Run 939 | Loss: 0.0022184746339917183\n",
      "Run 940 | Loss: 0.0022181738168001175\n",
      "Run 941 | Loss: 0.002217876957729459\n",
      "Run 942 | Loss: 0.0022175826597958803\n",
      "Run 943 | Loss: 0.002217286266386509\n",
      "Run 944 | Loss: 0.002216993598267436\n",
      "Run 945 | Loss: 0.0022166939452290535\n",
      "Run 946 | Loss: 0.0022164005786180496\n",
      "Run 947 | Loss: 0.0022161013912409544\n",
      "Run 948 | Loss: 0.002215808490291238\n",
      "Run 949 | Loss: 0.0022155146580189466\n",
      "Run 950 | Loss: 0.0022152168676257133\n",
      "Run 951 | Loss: 0.0022149255964905024\n",
      "Run 952 | Loss: 0.002214631997048855\n",
      "Run 953 | Loss: 0.002214334672316909\n",
      "Run 954 | Loss: 0.002214043168351054\n",
      "Run 955 | Loss: 0.0022137488704174757\n",
      "Run 956 | Loss: 0.002213458763435483\n",
      "Run 957 | Loss: 0.0022131677251309156\n",
      "Run 958 | Loss: 0.002212870167568326\n",
      "Run 959 | Loss: 0.0022125770337879658\n",
      "Run 960 | Loss: 0.0022122878581285477\n",
      "Run 961 | Loss: 0.0022119919303804636\n",
      "Run 962 | Loss: 0.0022117013577371836\n",
      "Run 963 | Loss: 0.002211409853771329\n",
      "Run 964 | Loss: 0.002211120678111911\n",
      "Run 965 | Loss: 0.0022108282428234816\n",
      "Run 966 | Loss: 0.002210537903010845\n",
      "Run 967 | Loss: 0.0022102463990449905\n",
      "Run 968 | Loss: 0.0022099593188613653\n",
      "Run 969 | Loss: 0.0022096680477261543\n",
      "Run 970 | Loss: 0.002209377707913518\n",
      "Run 971 | Loss: 0.002209089696407318\n",
      "Run 972 | Loss: 0.0022087995894253254\n",
      "Run 973 | Loss: 0.0022085048258304596\n",
      "Run 974 | Loss: 0.0022082228679209948\n",
      "Run 975 | Loss: 0.0022079269401729107\n",
      "Run 976 | Loss: 0.002207638695836067\n",
      "Run 977 | Loss: 0.002207352314144373\n",
      "Run 978 | Loss: 0.002207063836976886\n",
      "Run 979 | Loss: 0.0022067741956561804\n",
      "Run 980 | Loss: 0.002206492470577359\n",
      "Run 981 | Loss: 0.0022062042262405157\n",
      "Run 982 | Loss: 0.0022059171460568905\n",
      "Run 983 | Loss: 0.0022056291345506907\n",
      "Run 984 | Loss: 0.0022053420543670654\n",
      "Run 985 | Loss: 0.0022050540428608656\n",
      "Run 986 | Loss: 0.0022047667298465967\n",
      "Run 987 | Loss: 0.0022044803481549025\n",
      "Run 988 | Loss: 0.0022041983902454376\n",
      "Run 989 | Loss: 0.002203912939876318\n",
      "Run 990 | Loss: 0.0022036239970475435\n",
      "Run 991 | Loss: 0.002203339245170355\n",
      "Run 992 | Loss: 0.002203051233664155\n",
      "Run 993 | Loss: 0.002202768111601472\n",
      "Run 994 | Loss: 0.002202484058216214\n",
      "Run 995 | Loss: 0.0022021958138793707\n",
      "Run 996 | Loss: 0.0022019168827682734\n",
      "Run 997 | Loss: 0.002201630501076579\n",
      "Run 998 | Loss: 0.0022013431880623102\n",
      "Run 999 | Loss: 0.0022010647226125\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "tensor([0.5000, 1.0000])\n",
      "Output: \n",
      "tensor([0.9362])\n"
     ]
    }
   ],
   "source": [
    "# Completion of exercise from:\n",
    "# https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# (study, sleep) hours\n",
    "x = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float)\n",
    "# grades\n",
    "y = torch.tensor(([92], [100], [89]), dtype=torch.float)\n",
    "# (study, sleep) input for which we want to predict a grade\n",
    "xPred = torch.tensor(([4, 8]), dtype=torch.float)\n",
    "\n",
    "x_max, _ = torch.max(x, 0)\n",
    "xPred_max, _ = torch.max(xPred, 0)\n",
    "\n",
    "# Normalization\n",
    "x = torch.div(x, x_max)\n",
    "xPred = torch.div(xPred, xPred_max)\n",
    "y = y/100 # max score = 100%\n",
    "\n",
    "# ========================================== Neural net definition ===========================================\n",
    "class Net(nn.Module):\n",
    "    # Net contains input, output, and a single hidden layer\n",
    "    def __init__(self, name, i, o, h):\n",
    "        super(Net, self).__init__()\n",
    "        # parameters\n",
    "        self.name = name\n",
    "        self.inSize = i\n",
    "        self.outSize = o\n",
    "        self.hidSize = h\n",
    "        \n",
    "        # initialize weights randomly\n",
    "        self.inWeights = torch.randn(self.inSize, self.hidSize)\n",
    "        self.outWeights = torch.randn(self.hidSize, self.outSize)\n",
    "\n",
    "    # Forward: input -(inWeights)-> hidden -(outWeights)-> output\n",
    "    def forward(self, x):\n",
    "        # input -(inWeights)-> hidden\n",
    "        self.z = x.matmul(self.inWeights)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        #hidden -(outWeights)-> output\n",
    "        self.z3 = self.z2.matmul(self.outWeights)\n",
    "        out = self.sigmoid(self.z3)\n",
    "        return out\n",
    "    \n",
    "    # Backpropogation\n",
    "    def backward(self, x, y, out):\n",
    "        # Difference between actual and expected output\n",
    "        self.outErr = y - out\n",
    "        self.outDelta = self.outErr * self.sigmoidPrime(out)\n",
    "        self.z2Err = self.outDelta.matmul(self.outWeights.t())\n",
    "        self.z2Delta = self.z2Err * self.sigmoidPrime(self.z2)\n",
    "        # Update weights\n",
    "        self.inWeights += x.t().matmul(self.z2Delta)\n",
    "        self.outWeights += self.z2.matmul(self.outDelta)\n",
    "        \n",
    "    # Abstracted training method\n",
    "    def train(self, input, output):\n",
    "        out = self.forward(input)\n",
    "        self.backward(input, output, out)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        torch.save(model, self.name)\n",
    "\n",
    "    # Implementation of sigmoid activation function\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    # Derivative of sigmoid\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "# ====================================== End of neural net definition =========================================\n",
    "\n",
    "net = Net(\"toy net 2\", 2, 1, 3)\n",
    "# Train N times\n",
    "N = 1000\n",
    "for i in range(N):\n",
    "    # print(\"Run \" + str(i) + \" | Loss: \" + str(torch.mean((y - net(x))**2).detach().item()))\n",
    "    net.train(x,y)\n",
    "\n",
    "net.saveWeights(net)\n",
    "\n",
    "# Test prediction\n",
    "print (\"Predicted data based on trained weights: \")\n",
    "print (\"Input (scaled): \\n\" + str(xPred))\n",
    "print (\"Output: \\n\" + str(net.forward(xPred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
