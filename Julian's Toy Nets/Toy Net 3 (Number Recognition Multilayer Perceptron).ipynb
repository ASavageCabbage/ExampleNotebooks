{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Neural Net (Multilayer Perceptron with Autograd Backpropogation)\n",
    "\n",
    "Goal: Train a multilayer perceptron to recognize numbers from images using the MNIST database.\n",
    "\n",
    "Made with help from:\n",
    "- https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "- https://github.com/WatChMaL/ExampleNotebooks/blob/master/MNIST%20MLP.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the MNIST database\n",
    "\n",
    "Initializing a trainLoader and testLoader for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Set parameters for dataset to fetch\n",
    "trainBatchSize = 20\n",
    "testBatchSize = 1000\n",
    "\n",
    "# Fetch datasets and build locally\n",
    "dataset = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                                     transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "trainLoader = torch.utils.data.DataLoader(dataset, batch_size=trainBatchSize, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset, batch_size=testBatchSize, shuffle=True)\n",
    "\n",
    "\n",
    "# Fetch datasets (28x28 pixels) (does not work on ComputeCanada)\n",
    "#trainLoader = torch.utils.data.DataLoader(\n",
    "#  torchvision.datasets.MNIST('/files/', train=True, download=False,\n",
    "#                             transform=torchvision.transforms.Compose([\n",
    "#                               torchvision.transforms.ToTensor()])),\n",
    "#  batch_size=trainBatchSize, shuffle=True)\n",
    "\n",
    "#testLoader = torch.utils.data.DataLoader(\n",
    "#  torchvision.datasets.MNIST('/files/', train=False, download=False,\n",
    "#                             transform=torchvision.transforms.Compose([\n",
    "#                               torchvision.transforms.ToTensor()])),\n",
    "#  batch_size=testBatchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the test data for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = enumerate(testLoader)\n",
    "idx, (exampleData, exampleTargets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(exampleData[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(exampleTargets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Implementation\n",
    "\n",
    "Time to implement the neural net. Somewhat arbitrarily, I decided to use an MLP with 2 hidden layers of 500, then 100 neurons, with an input layer of 28x28 = 784 neurons and an output layer of 10 neurons corresponding to the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # Constructor initializes two hidden layers with neuron counts specified by the user\n",
    "    def __init__(self, L1, L2):\n",
    "        super(MLP, self).__init__()\n",
    "        # input -(W1)-> L1 -(W2)-> L2 -(W3)-> output\n",
    "        self._classifier = nn.Sequential(\n",
    "            nn.Linear(28*28, L1), nn.ReLU(),\n",
    "            nn.Linear(L1, L2), nn.ReLU(),\n",
    "            nn.Linear(L2, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten 2d input into 1d array:\n",
    "        x_flat = x.view(-1, np.prod(x.size()[1:]))\n",
    "        # Run through classifier\n",
    "        return self._classifier(x_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a BLOB class to organize training objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty class definition\n",
    "class BLOB:\n",
    "    pass\n",
    "# Dynamic attribute allocation\n",
    "blob = BLOB()\n",
    "blob.net = MLP(128, 128) # HERE SHE IS\n",
    "blob.errFn = nn.CrossEntropyLoss() # Error-defining function is softmax\n",
    "blob.optim = torch.optim.Adam(blob.net.parameters()) # Adam optimizer algorithm\n",
    "blob.iter = 0 # training iteration number\n",
    "blob.data = None # data for training/analysis\n",
    "blob.expect = None # correct values\n",
    "\n",
    "# Forward evolution function\n",
    "# REQUIRES: blob arg must have all attributes set\n",
    "def forward(blob, train=True):\n",
    "    with torch.set_grad_enabled(train):\n",
    "        # Get prediction from MLP\n",
    "        pred = blob.net(blob.data)\n",
    "        # Training stuff\n",
    "        loss = -1\n",
    "        if blob.expect is not None:\n",
    "            # blob.expect.requires_grad(False) # Something odd is happening on this line, commenting it out seems to work\n",
    "            loss = blob.errFn(pred, blob.expect)\n",
    "        # Another dynamically assigned attribute\n",
    "        blob.loss = loss\n",
    "        \n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        correctTensor = (pred == blob.expect) # Tensor of booleans corresponding to correct predictions\n",
    "        acc = correctTensor.sum().item() / float(pred.nelement()) # Accuracy of MLP\n",
    "        \n",
    "        return {'prediction' : pred.detach().numpy(),\n",
    "                'loss'       : loss.detach().item(),\n",
    "                'accuracy'   : acc}\n",
    "    \n",
    "# Backprop initialization\n",
    "# REQUIRES: blob arg must first have been run through forward\n",
    "def backward(blob):\n",
    "    blob.optim.zero_grad()\n",
    "    blob.loss.backward()\n",
    "    blob.optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "And now for the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t| Loss: 2.2989249229431152 \t| Accuracy: 0.1\n",
      "Iteration: 10 \t| Loss: 2.091398000717163 \t| Accuracy: 0.45\n",
      "Iteration: 20 \t| Loss: 2.1019856929779053 \t| Accuracy: 0.4\n",
      "Iteration: 30 \t| Loss: 1.6761448383331299 \t| Accuracy: 0.35\n",
      "Iteration: 40 \t| Loss: 0.9298934936523438 \t| Accuracy: 0.85\n",
      "Iteration: 50 \t| Loss: 0.757409393787384 \t| Accuracy: 0.9\n",
      "Iteration: 60 \t| Loss: 0.7806510925292969 \t| Accuracy: 0.7\n",
      "Iteration: 70 \t| Loss: 0.8691949844360352 \t| Accuracy: 0.8\n",
      "Iteration: 80 \t| Loss: 0.7263573408126831 \t| Accuracy: 0.85\n",
      "Iteration: 90 \t| Loss: 0.47780856490135193 \t| Accuracy: 0.85\n",
      "Iteration: 100 \t| Loss: 0.437007337808609 \t| Accuracy: 0.9\n",
      "Iteration: 110 \t| Loss: 0.3399107754230499 \t| Accuracy: 0.9\n",
      "Iteration: 120 \t| Loss: 0.60759037733078 \t| Accuracy: 0.85\n",
      "Iteration: 130 \t| Loss: 0.41110140085220337 \t| Accuracy: 0.85\n",
      "Iteration: 140 \t| Loss: 0.36324018239974976 \t| Accuracy: 0.95\n",
      "Iteration: 150 \t| Loss: 0.30307653546333313 \t| Accuracy: 0.8\n",
      "Iteration: 160 \t| Loss: 0.40069514513015747 \t| Accuracy: 0.85\n",
      "Iteration: 170 \t| Loss: 0.32923388481140137 \t| Accuracy: 0.95\n",
      "Iteration: 180 \t| Loss: 0.41987818479537964 \t| Accuracy: 0.9\n",
      "Iteration: 190 \t| Loss: 0.6387851238250732 \t| Accuracy: 0.75\n",
      "Iteration: 200 \t| Loss: 0.46451109647750854 \t| Accuracy: 0.85\n",
      "Iteration: 210 \t| Loss: 0.36506372690200806 \t| Accuracy: 0.95\n",
      "Iteration: 220 \t| Loss: 0.12076625972986221 \t| Accuracy: 1.0\n",
      "Iteration: 230 \t| Loss: 0.3496754467487335 \t| Accuracy: 0.95\n",
      "Iteration: 240 \t| Loss: 0.2041996419429779 \t| Accuracy: 0.95\n",
      "Iteration: 250 \t| Loss: 0.1765047013759613 \t| Accuracy: 0.95\n",
      "Iteration: 260 \t| Loss: 0.0813426524400711 \t| Accuracy: 1.0\n",
      "Iteration: 270 \t| Loss: 0.41457170248031616 \t| Accuracy: 0.85\n",
      "Iteration: 280 \t| Loss: 0.11928921937942505 \t| Accuracy: 1.0\n",
      "Iteration: 290 \t| Loss: 0.29701805114746094 \t| Accuracy: 0.95\n",
      "Iteration: 300 \t| Loss: 0.2522507607936859 \t| Accuracy: 0.9\n",
      "Iteration: 310 \t| Loss: 0.40561026334762573 \t| Accuracy: 0.9\n",
      "Iteration: 320 \t| Loss: 0.2412232607603073 \t| Accuracy: 0.9\n",
      "Iteration: 330 \t| Loss: 0.2091774195432663 \t| Accuracy: 0.95\n",
      "Iteration: 340 \t| Loss: 0.25918132066726685 \t| Accuracy: 0.95\n",
      "Iteration: 350 \t| Loss: 0.6200701594352722 \t| Accuracy: 0.9\n",
      "Iteration: 360 \t| Loss: 0.24531221389770508 \t| Accuracy: 0.95\n",
      "Iteration: 370 \t| Loss: 0.13818594813346863 \t| Accuracy: 0.95\n",
      "Iteration: 380 \t| Loss: 0.2073650062084198 \t| Accuracy: 0.95\n",
      "Iteration: 390 \t| Loss: 0.3505893647670746 \t| Accuracy: 0.95\n",
      "Iteration: 400 \t| Loss: 0.14256730675697327 \t| Accuracy: 0.95\n",
      "Iteration: 410 \t| Loss: 0.19500744342803955 \t| Accuracy: 0.9\n",
      "Iteration: 420 \t| Loss: 0.8379189372062683 \t| Accuracy: 0.75\n",
      "Iteration: 430 \t| Loss: 0.34390461444854736 \t| Accuracy: 0.85\n",
      "Iteration: 440 \t| Loss: 0.1043163537979126 \t| Accuracy: 1.0\n",
      "Iteration: 450 \t| Loss: 0.187583789229393 \t| Accuracy: 0.9\n",
      "Iteration: 460 \t| Loss: 0.8751538991928101 \t| Accuracy: 0.8\n",
      "Iteration: 470 \t| Loss: 0.4436565339565277 \t| Accuracy: 0.8\n",
      "Iteration: 480 \t| Loss: 0.24375271797180176 \t| Accuracy: 0.95\n",
      "Iteration: 490 \t| Loss: 0.5872359275817871 \t| Accuracy: 0.85\n",
      "Iteration: 500 \t| Loss: 0.22302424907684326 \t| Accuracy: 0.85\n",
      "Iteration: 510 \t| Loss: 0.1934252679347992 \t| Accuracy: 0.95\n",
      "Iteration: 520 \t| Loss: 0.6074245572090149 \t| Accuracy: 0.8\n",
      "Iteration: 530 \t| Loss: 0.22354796528816223 \t| Accuracy: 0.95\n",
      "Iteration: 540 \t| Loss: 0.23995666205883026 \t| Accuracy: 0.85\n",
      "Iteration: 550 \t| Loss: 0.10529766231775284 \t| Accuracy: 0.95\n",
      "Iteration: 560 \t| Loss: 0.27648869156837463 \t| Accuracy: 0.9\n",
      "Iteration: 570 \t| Loss: 0.12134356796741486 \t| Accuracy: 0.95\n",
      "Iteration: 580 \t| Loss: 0.48407015204429626 \t| Accuracy: 0.9\n",
      "Iteration: 590 \t| Loss: 0.09676351398229599 \t| Accuracy: 1.0\n",
      "Iteration: 600 \t| Loss: 0.28501105308532715 \t| Accuracy: 0.85\n",
      "Iteration: 610 \t| Loss: 0.5592513084411621 \t| Accuracy: 0.85\n",
      "Iteration: 620 \t| Loss: 0.3444519340991974 \t| Accuracy: 0.9\n",
      "Iteration: 630 \t| Loss: 0.0962650403380394 \t| Accuracy: 1.0\n",
      "Iteration: 640 \t| Loss: 0.28188976645469666 \t| Accuracy: 0.85\n",
      "Iteration: 650 \t| Loss: 0.10077778249979019 \t| Accuracy: 1.0\n",
      "Iteration: 660 \t| Loss: 0.08850858360528946 \t| Accuracy: 1.0\n",
      "Iteration: 670 \t| Loss: 0.3413715064525604 \t| Accuracy: 0.9\n",
      "Iteration: 680 \t| Loss: 0.13888147473335266 \t| Accuracy: 1.0\n",
      "Iteration: 690 \t| Loss: 0.10443516820669174 \t| Accuracy: 0.95\n",
      "Iteration: 700 \t| Loss: 0.21368786692619324 \t| Accuracy: 0.85\n",
      "Iteration: 710 \t| Loss: 0.39617571234703064 \t| Accuracy: 0.9\n",
      "Iteration: 720 \t| Loss: 0.6693623065948486 \t| Accuracy: 0.9\n",
      "Iteration: 730 \t| Loss: 0.14682160317897797 \t| Accuracy: 0.95\n",
      "Iteration: 740 \t| Loss: 0.42901620268821716 \t| Accuracy: 0.9\n",
      "Iteration: 750 \t| Loss: 0.2528960108757019 \t| Accuracy: 0.9\n",
      "Iteration: 760 \t| Loss: 0.2051098644733429 \t| Accuracy: 0.95\n",
      "Iteration: 770 \t| Loss: 0.05588029697537422 \t| Accuracy: 1.0\n",
      "Iteration: 780 \t| Loss: 0.1431335061788559 \t| Accuracy: 0.95\n",
      "Iteration: 790 \t| Loss: 0.18880556523799896 \t| Accuracy: 0.95\n",
      "Iteration: 800 \t| Loss: 0.2787284553050995 \t| Accuracy: 0.9\n",
      "Iteration: 810 \t| Loss: 0.2184761017560959 \t| Accuracy: 0.9\n",
      "Iteration: 820 \t| Loss: 0.1812632530927658 \t| Accuracy: 0.9\n",
      "Iteration: 830 \t| Loss: 0.3150484263896942 \t| Accuracy: 0.85\n",
      "Iteration: 840 \t| Loss: 0.29048073291778564 \t| Accuracy: 0.9\n",
      "Iteration: 850 \t| Loss: 0.17146806418895721 \t| Accuracy: 0.9\n",
      "Iteration: 860 \t| Loss: 0.11683224141597748 \t| Accuracy: 0.95\n",
      "Iteration: 870 \t| Loss: 0.7370662093162537 \t| Accuracy: 0.8\n",
      "Iteration: 880 \t| Loss: 0.12017764896154404 \t| Accuracy: 0.95\n",
      "Iteration: 890 \t| Loss: 0.4693201184272766 \t| Accuracy: 0.9\n",
      "Iteration: 900 \t| Loss: 0.05561809614300728 \t| Accuracy: 1.0\n",
      "Iteration: 910 \t| Loss: 0.173968106508255 \t| Accuracy: 0.9\n",
      "Iteration: 920 \t| Loss: 0.22005732357501984 \t| Accuracy: 0.95\n",
      "Iteration: 930 \t| Loss: 0.29379981756210327 \t| Accuracy: 0.9\n",
      "Iteration: 940 \t| Loss: 0.06273076683282852 \t| Accuracy: 1.0\n",
      "Iteration: 950 \t| Loss: 0.1496410220861435 \t| Accuracy: 1.0\n",
      "Iteration: 960 \t| Loss: 0.07937709242105484 \t| Accuracy: 1.0\n",
      "Iteration: 970 \t| Loss: 0.07550064474344254 \t| Accuracy: 1.0\n",
      "Iteration: 980 \t| Loss: 0.3044006824493408 \t| Accuracy: 0.9\n",
      "Iteration: 990 \t| Loss: 0.0993821769952774 \t| Accuracy: 0.95\n",
      "Iteration: 1000 \t| Loss: 0.04396245628595352 \t| Accuracy: 1.0\n",
      "Iteration: 1010 \t| Loss: 0.46141132712364197 \t| Accuracy: 0.85\n",
      "Iteration: 1020 \t| Loss: 0.5952638387680054 \t| Accuracy: 0.8\n",
      "Iteration: 1030 \t| Loss: 0.32265204191207886 \t| Accuracy: 0.9\n",
      "Iteration: 1040 \t| Loss: 0.08880788087844849 \t| Accuracy: 0.95\n",
      "Iteration: 1050 \t| Loss: 0.050136495381593704 \t| Accuracy: 1.0\n",
      "Iteration: 1060 \t| Loss: 0.3363216519355774 \t| Accuracy: 0.9\n",
      "Iteration: 1070 \t| Loss: 0.15097209811210632 \t| Accuracy: 0.95\n",
      "Iteration: 1080 \t| Loss: 0.29662424325942993 \t| Accuracy: 0.9\n",
      "Iteration: 1090 \t| Loss: 0.1302632987499237 \t| Accuracy: 1.0\n",
      "Iteration: 1100 \t| Loss: 0.1446051448583603 \t| Accuracy: 0.95\n",
      "Iteration: 1110 \t| Loss: 0.06456754356622696 \t| Accuracy: 1.0\n",
      "Iteration: 1120 \t| Loss: 0.3918713629245758 \t| Accuracy: 0.85\n",
      "Iteration: 1130 \t| Loss: 0.03109586238861084 \t| Accuracy: 1.0\n",
      "Iteration: 1140 \t| Loss: 0.2622787356376648 \t| Accuracy: 0.9\n",
      "Iteration: 1150 \t| Loss: 0.37618288397789 \t| Accuracy: 0.9\n",
      "Iteration: 1160 \t| Loss: 0.072720006108284 \t| Accuracy: 1.0\n",
      "Iteration: 1170 \t| Loss: 0.15876254439353943 \t| Accuracy: 0.95\n",
      "Iteration: 1180 \t| Loss: 0.34943875670433044 \t| Accuracy: 0.85\n",
      "Iteration: 1190 \t| Loss: 0.04948385804891586 \t| Accuracy: 1.0\n",
      "Iteration: 1200 \t| Loss: 0.10711459070444107 \t| Accuracy: 0.95\n",
      "Iteration: 1210 \t| Loss: 0.4193144738674164 \t| Accuracy: 0.85\n",
      "Iteration: 1220 \t| Loss: 0.7745989561080933 \t| Accuracy: 0.8\n",
      "Iteration: 1230 \t| Loss: 0.27592894434928894 \t| Accuracy: 0.95\n",
      "Iteration: 1240 \t| Loss: 0.22429612278938293 \t| Accuracy: 0.9\n",
      "Iteration: 1250 \t| Loss: 0.040898703038692474 \t| Accuracy: 1.0\n",
      "Iteration: 1260 \t| Loss: 0.10117640346288681 \t| Accuracy: 1.0\n",
      "Iteration: 1270 \t| Loss: 0.11469998210668564 \t| Accuracy: 0.95\n",
      "Iteration: 1280 \t| Loss: 0.15638655424118042 \t| Accuracy: 0.9\n",
      "Iteration: 1290 \t| Loss: 0.12877757847309113 \t| Accuracy: 0.95\n",
      "Iteration: 1300 \t| Loss: 0.33923906087875366 \t| Accuracy: 0.9\n",
      "Iteration: 1310 \t| Loss: 0.11862458288669586 \t| Accuracy: 0.95\n",
      "Iteration: 1320 \t| Loss: 0.3140528202056885 \t| Accuracy: 0.85\n",
      "Iteration: 1330 \t| Loss: 0.35195666551589966 \t| Accuracy: 0.9\n",
      "Iteration: 1340 \t| Loss: 0.38504543900489807 \t| Accuracy: 0.85\n",
      "Iteration: 1350 \t| Loss: 0.42783457040786743 \t| Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1360 \t| Loss: 0.03708387538790703 \t| Accuracy: 1.0\n",
      "Iteration: 1370 \t| Loss: 0.07793104648590088 \t| Accuracy: 1.0\n",
      "Iteration: 1380 \t| Loss: 0.5987817645072937 \t| Accuracy: 0.8\n",
      "Iteration: 1390 \t| Loss: 0.10455223172903061 \t| Accuracy: 0.95\n",
      "Iteration: 1400 \t| Loss: 0.6463900804519653 \t| Accuracy: 0.85\n",
      "Iteration: 1410 \t| Loss: 0.3721548318862915 \t| Accuracy: 0.9\n",
      "Iteration: 1420 \t| Loss: 0.05989720672369003 \t| Accuracy: 1.0\n",
      "Iteration: 1430 \t| Loss: 0.13072408735752106 \t| Accuracy: 1.0\n",
      "Iteration: 1440 \t| Loss: 0.12356019020080566 \t| Accuracy: 0.95\n",
      "Iteration: 1450 \t| Loss: 0.09168006479740143 \t| Accuracy: 0.95\n",
      "Iteration: 1460 \t| Loss: 0.2217995822429657 \t| Accuracy: 0.9\n",
      "Iteration: 1470 \t| Loss: 0.28302714228630066 \t| Accuracy: 0.9\n",
      "Iteration: 1480 \t| Loss: 0.02679530344903469 \t| Accuracy: 1.0\n",
      "Iteration: 1490 \t| Loss: 0.25689223408699036 \t| Accuracy: 0.95\n",
      "Iteration: 1500 \t| Loss: 0.09693864732980728 \t| Accuracy: 0.95\n",
      "Iteration: 1510 \t| Loss: 0.0887162834405899 \t| Accuracy: 1.0\n",
      "Iteration: 1520 \t| Loss: 0.40490084886550903 \t| Accuracy: 0.9\n",
      "Iteration: 1530 \t| Loss: 0.04687068611383438 \t| Accuracy: 1.0\n",
      "Iteration: 1540 \t| Loss: 0.6074260473251343 \t| Accuracy: 0.85\n",
      "Iteration: 1550 \t| Loss: 0.16187375783920288 \t| Accuracy: 0.9\n",
      "Iteration: 1560 \t| Loss: 0.12142200767993927 \t| Accuracy: 0.95\n",
      "Iteration: 1570 \t| Loss: 0.013310718350112438 \t| Accuracy: 1.0\n",
      "Iteration: 1580 \t| Loss: 0.28108662366867065 \t| Accuracy: 0.9\n",
      "Iteration: 1590 \t| Loss: 0.05653496831655502 \t| Accuracy: 1.0\n",
      "Iteration: 1600 \t| Loss: 0.05242281034588814 \t| Accuracy: 1.0\n",
      "Iteration: 1610 \t| Loss: 0.0765276551246643 \t| Accuracy: 1.0\n",
      "Iteration: 1620 \t| Loss: 0.2765698730945587 \t| Accuracy: 0.9\n",
      "Iteration: 1630 \t| Loss: 0.020756090059876442 \t| Accuracy: 1.0\n",
      "Iteration: 1640 \t| Loss: 0.2790175676345825 \t| Accuracy: 0.85\n",
      "Iteration: 1650 \t| Loss: 0.2478567361831665 \t| Accuracy: 0.95\n",
      "Iteration: 1660 \t| Loss: 0.47197073698043823 \t| Accuracy: 0.9\n",
      "Iteration: 1670 \t| Loss: 0.11051265895366669 \t| Accuracy: 0.95\n",
      "Iteration: 1680 \t| Loss: 0.13967962563037872 \t| Accuracy: 0.95\n",
      "Iteration: 1690 \t| Loss: 0.20436421036720276 \t| Accuracy: 0.9\n",
      "Iteration: 1700 \t| Loss: 0.019865477457642555 \t| Accuracy: 1.0\n",
      "Iteration: 1710 \t| Loss: 0.04554120451211929 \t| Accuracy: 1.0\n",
      "Iteration: 1720 \t| Loss: 0.01008372288197279 \t| Accuracy: 1.0\n",
      "Iteration: 1730 \t| Loss: 0.3339284360408783 \t| Accuracy: 0.9\n",
      "Iteration: 1740 \t| Loss: 0.15961036086082458 \t| Accuracy: 0.95\n",
      "Iteration: 1750 \t| Loss: 0.19901874661445618 \t| Accuracy: 0.95\n",
      "Iteration: 1760 \t| Loss: 0.37749457359313965 \t| Accuracy: 0.95\n",
      "Iteration: 1770 \t| Loss: 0.11773498356342316 \t| Accuracy: 0.95\n",
      "Iteration: 1780 \t| Loss: 0.4452652037143707 \t| Accuracy: 0.8\n",
      "Iteration: 1790 \t| Loss: 0.5932306051254272 \t| Accuracy: 0.75\n",
      "Iteration: 1800 \t| Loss: 0.38718825578689575 \t| Accuracy: 0.9\n",
      "Iteration: 1810 \t| Loss: 0.028253566473722458 \t| Accuracy: 1.0\n",
      "Iteration: 1820 \t| Loss: 0.2745087742805481 \t| Accuracy: 0.9\n",
      "Iteration: 1830 \t| Loss: 0.6381719708442688 \t| Accuracy: 0.8\n",
      "Iteration: 1840 \t| Loss: 0.2419939488172531 \t| Accuracy: 0.95\n",
      "Iteration: 1850 \t| Loss: 0.16309301555156708 \t| Accuracy: 0.95\n",
      "Iteration: 1860 \t| Loss: 0.264425128698349 \t| Accuracy: 0.95\n",
      "Iteration: 1870 \t| Loss: 0.01474848948419094 \t| Accuracy: 1.0\n",
      "Iteration: 1880 \t| Loss: 0.31910476088523865 \t| Accuracy: 0.9\n",
      "Iteration: 1890 \t| Loss: 0.20481963455677032 \t| Accuracy: 0.9\n",
      "Iteration: 1900 \t| Loss: 0.1833239048719406 \t| Accuracy: 0.9\n",
      "Iteration: 1910 \t| Loss: 0.057176243513822556 \t| Accuracy: 1.0\n",
      "Iteration: 1920 \t| Loss: 0.28771036863327026 \t| Accuracy: 0.85\n",
      "Iteration: 1930 \t| Loss: 0.1709328442811966 \t| Accuracy: 0.95\n",
      "Iteration: 1940 \t| Loss: 0.05214369297027588 \t| Accuracy: 1.0\n",
      "Iteration: 1950 \t| Loss: 0.025345992296934128 \t| Accuracy: 1.0\n",
      "Iteration: 1960 \t| Loss: 0.3495940864086151 \t| Accuracy: 0.95\n",
      "Iteration: 1970 \t| Loss: 0.16892549395561218 \t| Accuracy: 0.95\n",
      "Iteration: 1980 \t| Loss: 0.0817025899887085 \t| Accuracy: 1.0\n",
      "Iteration: 1990 \t| Loss: 0.1000303253531456 \t| Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Set MLP to training mode\n",
    "blob.net.train()\n",
    "# Set number of training iterations\n",
    "maxIter = 2000\n",
    "# Set reporting interval\n",
    "repIter = 10\n",
    "# Training loop\n",
    "for i, data in enumerate(trainLoader):\n",
    "    blob.iter = i\n",
    "    # data consists of a list of two tensors [img data, values]\n",
    "    # unpack data into appropriate attributes in blob\n",
    "    blob.data, blob.expect = data\n",
    "    # test MLP\n",
    "    res = forward(blob)\n",
    "    # Report if current iteration is a multiple of the reporting interval\n",
    "    if (blob.iter % repIter) == 0:\n",
    "        print('Iteration:', blob.iter,'\\t| Loss:', res['loss'],'\\t| Accuracy:',res['accuracy'])\n",
    "    if (blob.iter + 1 >= maxIter):\n",
    "        break\n",
    "    # Backprop\n",
    "    backward(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Now to test the MLP on data it hasn't seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\taccuracy mean 0.9598166666666667 std 0.04435988866332086\n",
      "TEST\taccuracy mean 0.9598166666666667 std 0.005937147650363958\n"
     ]
    }
   ],
   "source": [
    "def evaluate(blob, loader):\n",
    "    # Set MLP to evalutation mode\n",
    "    blob.net.eval()\n",
    "    # Initialize result containers\n",
    "    accuracy, expected, prediction = [], [], []\n",
    "    for i, data in enumerate(loader):\n",
    "        blob.data, blob.expect = data\n",
    "        res = forward(blob)\n",
    "        accuracy.append(res['accuracy'])\n",
    "        prediction.append(res['prediction'])\n",
    "        expected.append(blob.expect)\n",
    "    # Organize result arrays\n",
    "    accuracy = np.hstack(accuracy)\n",
    "    expected = np.hstack(expected)\n",
    "    prediction = np.hstack(prediction)\n",
    "    return accuracy, expected, prediction\n",
    "\n",
    "# For the training set:\n",
    "accuracy, label, prediction = evaluate(blob, trainLoader)\n",
    "print(\"TRAIN\\taccuracy mean\",accuracy.mean(),\"std\",accuracy.std())\n",
    "\n",
    "# For the testing set:\n",
    "accuracy, label, prediction = evaluate(blob, testLoader)\n",
    "print(\"TEST\\taccuracy mean\",accuracy.mean(),\"std\",accuracy.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY! My first real neural net!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
